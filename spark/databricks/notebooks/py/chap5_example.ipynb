{"cells":[{"cell_type":"markdown","source":["# **Learning Spark Chapter 5, Loading and Saving your Data, Examples in Python**\n\n[![Learning Spark](http://akamaicovers.oreilly.com/images/0636920028512/cat.gif)](http://www.jdoqocy.com/click-7645222-11260198?url=http%3A%2F%2Fshop.oreilly.com%2Fproduct%2F0636920028512.do%3Fcmp%3Daf-strata-books-videos-product_cj_9781449358600_%2525zp&cjsku=0636920028512)\n\nMany of the examples in Chapter 5 require access to certain storage systems, these examples have been left out. For Databricks Cloud you should consider using the table creation mechanism."],"metadata":{}},{"cell_type":"markdown","source":["## S3 setup\n\nNote: If you have '/' characters in your secret access key, they must be escaped with '%2F'"],"metadata":{}},{"cell_type":"code","source":["ACCESS_KEY = \"YOUR ACCESS KEY GOES HERE\"\nSECRET_KEY = \"YOUR SECRET KEY GOES HERE\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Example 5-1. Python load text file example"],"metadata":{}},{"cell_type":"markdown","source":["Read all text files from the directory and do a word count on them. With the (k,v) pair RDD, make Rows of RDDs and create a dataframe. \nSave it as a temp table and issue some example queries"],"metadata":{}},{"cell_type":"code","source":["from pyspark import Row\nfrom pyspark.sql import *\n\ninput = sc.textFile(\"file:///dbfs/learning-spark-master/files/*.txt\")\ninputWords = input.flatMap(lambda l: l.split()).map(lambda w: w.lower())\npairs = inputWords.map(lambda w: (w, 1))\nwordCount = pairs.reduceByKey(lambda x, y: x + y)\nwordRowRDD = wordCount.map(lambda p: Row(word= p[0], value=p[1]))\nwordDF = sqlContext.createDataFrame(wordRowRDD)\ndisplay(wordDF)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Register dataframe as a temporary table"],"metadata":{}},{"cell_type":"code","source":["wordDF.registerTempTable(\"wordcount\")"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Issue some SQL queries"],"metadata":{}},{"cell_type":"code","source":["%sql select word, value from wordcount where value >= 5"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["display (wordDF)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["## Example 5-6. Python load unstructured JSON example"],"metadata":{}},{"cell_type":"code","source":["# Import SparkFiles\nfrom pyspark import SparkFiles\nimport json\n# Fetch the remote example since it isn't on local FS or S3\n# Load the file into an RDD\njsonInput = sc.textFile(\"file:///dbfs/learning-spark-master/files/testweet.json\")\njsonInput.collect()\n#Parse it\ndata = jsonInput.map(lambda x: json.loads(x))\n# Collect the parsed results back to the driver\ndata.collect()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"chap5_example","notebookId":87878},"nbformat":4,"nbformat_minor":0}
